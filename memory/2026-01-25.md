# 2026-01-25

## Local LLM Setup
- Installed Ollama on sam-server (RTX 3090, 24GB VRAM)
- Pulled llama3.2 (8B parameter model, ~2GB)
- Configured Clawdbot to use `ollama/llama3.2` for subagents (saves API credits)
- Ollama runs as systemd service, API at localhost:11434

## Config Changes
- Added `models.providers.ollama` with OpenAI-compatible endpoint
- Set `agents.defaults.subagents.model` to `ollama/llama3.2`
- Cost: $0 for local inference

## Personal Notes
- Sam's wife is Dr. Crawford (showed her a quick "Hi Dr. Crawford" demo website)
- Sam completed passwordless sudo setup the night before (2026-01-24)

## Google Integration Complete
- Set up Google Cloud project (ID: 237883885846)
- OAuth credentials created for Gmail, Calendar, Drive, Photos
- **MCP servers configured** (mcporter):
  - `gmail` - @mcp-z/mcp-gmail
  - `drive` - @mcp-z/mcp-drive  
  - `calendar` - @cocal/google-calendar-mcp
- **rclone configured** for Drive sync (gdrive:)
- Photos API limitation: Google only allows downloading photos uploaded by same app
- **Workaround**: Google Takeout → Drive → auto-sync to Jellyfin

## Google Photos Backup Setup
- Destination: `/home/sam/media/pictures/google-photos-takeout/`
- Sam setting up Google Takeout (every 2 months → Drive)
- Auto-sync script: `/home/sam/media/pictures/sync-takeout-from-drive.sh`
- Cron: Daily at 4am checks Drive for new Takeout exports
- Jellyfin will pick up photos from pictures library
